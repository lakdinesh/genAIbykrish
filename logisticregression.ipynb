{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObNoehKvrEbTAPkvTG/8Ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakdinesh/genAIbykrish/blob/main/logisticregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "DEpzTNm2693_",
        "outputId": "e6673396-83d9-4651-e482-f694f3b886e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/genaikrish/logisticregdataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4002732700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/genaikrish/logisticregdataset.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m# Make sure to upload 'linear_regression_dataset.csv' to your Colab environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;31m#df = pd.read_csv(r'C:/Users/lakdi/Downloads/dataset.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/genaikrish/logisticregdataset.csv'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Linear logistic regression suitable for large datasets\n",
        "    P. Biedenkopf - 16.12.2020\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize as opt\n",
        "import logging\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "        Returns value of the sigmoid function for z\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-z));\n",
        "logging.basicConfig(filename=\"ERROR.log\",\n",
        "                    filemode='w',\n",
        "                    level=logging.ERROR)\n",
        "\n",
        "class LinearLogisticRegression:\n",
        "    \"\"\"\n",
        "        Logistic regression class.\n",
        "        members:\n",
        "            verbose     -   bool for getting detailed output\n",
        "            costHist    -   Objective function history list\n",
        "            method      -   optimization algorithm\n",
        "            OptMaxIter  -   Max iteration number\n",
        "            ftol        -   Stop criterion for optimization algorithm\n",
        "            iter        -   Current iteration, is initialized as 0\n",
        "            X           -   dataset for which a value gets predicted by the model\n",
        "            y           -   labels of dataset (vector)\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, method='L-BFGS-B', optMaxIter=300, verbose=False, ftol=1e-7):\n",
        "        self.X = np.insert(X, 0, np.ones(len(y)), axis=1) # leading ones-vector for constant term theta0\n",
        "        self.y = y\n",
        "        self.optMaxIter = optMaxIter\n",
        "        self.costHist = []\n",
        "        self.iter = 0\n",
        "        self.verbose = verbose\n",
        "        self.ftol = ftol\n",
        "        self.method = method\n",
        "        self.logger = logging.getLogger()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "            Trains the model for the dataset given in constructor.\n",
        "        \"\"\"\n",
        "        # initialize theta\n",
        "        self.theta = np.zeros(self.X.shape[1])\n",
        "\n",
        "        opts = {'disp': False, 'maxiter': self.optMaxIter, 'ftol': self.ftol}\n",
        "        sol = opt.minimize(self.costFun, self.theta, method=self.method, jac=self.costFunGrad, options=opts)\n",
        "        if sol.success:\n",
        "            print(\"Optimization succeeded: {} | Solution: {:e} | {}\".format(sol.success, sol.fun, sol.x))\n",
        "            self.theta = np.array(sol.x)\n",
        "            self.accuracy()\n",
        "\n",
        "        if self.verbose:\n",
        "            self.plotConvergence()\n",
        "            print(f'Model accuracy is: {self.acc:.1f}% on training data')\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "            Predicts value for a given datapoint x.\n",
        "            variables:\n",
        "                t - datapoint for which a value gets predicted by the model\n",
        "        \"\"\"\n",
        "        x = np.insert(x, 0, 1)\n",
        "        prob = sigmoid(x.dot(self.theta));\n",
        "        if self.verbose:\n",
        "            print(f'Prediction for {x[1:]} is: {100*prob:.1f}%')\n",
        "        return prob\n",
        "\n",
        "    def accuracy(self, threshold=0.5):\n",
        "        \"\"\"\n",
        "            Computes the accuracy of the trained model for the training set.\n",
        "            variables:\n",
        "                threshold - threshold for accepting a value as 1\n",
        "        \"\"\"\n",
        "        p = np.zeros([len(self.y), ]);\n",
        "        for i in range(len(self.y)):\n",
        "            if sigmoid(self.X[i].dot(self.theta)) >= threshold:\n",
        "                p[i] = 1;\n",
        "            else:\n",
        "                p[i] = 0;\n",
        "\n",
        "        self.acc = np.mean(p == self.y) * 100\n",
        "\n",
        "    def costFun(self, theta):\n",
        "        \"\"\"\n",
        "                Returns objective value for measuring fitness of model.\n",
        "                variables:\n",
        "                    theta   - current model parameters\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            print(\"Iter: {} | theta: {}\".format(self.iter, theta))\n",
        "        J = 0\n",
        "        m = len(self.y)\n",
        "        # Using np.finfo(float).eps to avoid dividing by zero errors/warnings\n",
        "        cost = -self.y*np.log(sigmoid(self.X.dot(theta))+np.finfo(float).eps) - (np.ones([m,])-self.y)*np.log(1-sigmoid(self.X.dot(theta))+np.finfo(float).eps)\n",
        "        J = 1/m * sum(cost)\n",
        "\n",
        "        self.costHist.append(J)\n",
        "        self.theta = theta\n",
        "        self.iter += 1\n",
        "        return J\n",
        "\n",
        "    def costFunGrad(self, theta):\n",
        "        \"\"\"\n",
        "                Returns gradient of the objective.\n",
        "                variables:\n",
        "                    theta   - current model parameters\n",
        "        \"\"\"\n",
        "        Grad = np.zeros(theta.shape);\n",
        "        m = len(self.y)\n",
        "\n",
        "        for i in range(len(theta)):\n",
        "            Grad[i] = 1/m * sum( (sigmoid(self.X.dot(theta)) - self.y) * self.X[:,i] )\n",
        "\n",
        "        return Grad\n",
        "\n",
        "    def plotConvergence(self):\n",
        "        \"\"\"\n",
        "            Plots the convergence of the model over the iterations\n",
        "        \"\"\"\n",
        "        plt.figure(2)\n",
        "        plt.plot(range(0,len(self.costHist)), self.costHist)\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(\"Iteration\")\n",
        "        plt.ylabel(\"Objective\")\n",
        "        plt.title(\"Convergence\")\n",
        "        plt.legend()\n",
        "\n",
        "    def plotDecisionBoundary2D(self):\n",
        "        \"\"\"\n",
        "            Plots the dataset and the decision boundary of the model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            assert self.X.shape[1] == 3 # Method only valid for 2D problems\n",
        "        except:\n",
        "            self.logger.error(\"plotDecisionBoundary2D() method is only valid for 2-dimensional problems!\")\n",
        "            logging.shutdown()\n",
        "            raise AssertionError(\"plotDecisionBoundary2D() method is only valid for 2-dimensional problems!\")\n",
        "\n",
        "        plt.figure(3)\n",
        "        X1 = self.X[:,1]\n",
        "        X2 = self.X[:,2]\n",
        "        pos = np.where(self.y == 1)\n",
        "        neg = np.where(self.y == 0)\n",
        "        plt.scatter(X1[pos], X2[pos], label='positive', marker='.', color='b')\n",
        "        plt.scatter(X1[neg], X2[neg], label='negative', marker='+', color='r')\n",
        "        plt.xlabel(r'$X_2$')\n",
        "        plt.ylabel(r'$X_1$')\n",
        "\n",
        "        # decision boundary\n",
        "        x = np.linspace(np.amin(X1), np.amax(X1))\n",
        "        y = (-1/self.theta[2])*(self.theta[1]*x + self.theta[0])\n",
        "        plt.plot(x, y, label=\"Decision Boundary\", color='black')\n",
        "        plt.legend()\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Logistic Regression with regularisation: {} and max. {} Iterations.\".format(self.Lambda, self.optMaxIter)\n",
        "\n",
        "import pandas as pd\n",
        "# Make sure to upload 'linear_regression_dataset.csv' to your Colab environment\n",
        "file_path = '/content/drive/My Drive/genaikrish/logisticregdataset.csv'\n",
        "# Make sure to upload 'linear_regression_dataset.csv' to your Colab environment\n",
        "df = pd.read_csv(file_path,sep=\";\")\n",
        "#df = pd.read_csv(r'C:/Users/lakdi/Downloads/dataset.csv')\n",
        "data = np.genfromtxt(df, delimiter=',', skip_header=1)\n",
        "y = data[:,2]\n",
        "X = data[:,:2]\n",
        "\n",
        "# Create algorithm instance\n",
        "model = LinearLogisticRegression(X, y, verbose=True, method='L-BFGS-B')\n",
        "\n",
        "# Fit model with training data\n",
        "model.train()\n",
        "model.plotDecisionBoundary2D()\n",
        "\n",
        "# Make prediction for new datapoint\n",
        "pred = [50, 85]\n",
        "model.predict(pred)"
      ]
    }
  ]
}